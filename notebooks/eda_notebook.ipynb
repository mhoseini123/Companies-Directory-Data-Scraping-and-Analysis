

# 0. Set up Environment and Import Libraries

# Ensure you have installed required libraries:
# pip install -r requirements.txt

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

# Import your preprocessing functions
# If data_processor.py is in the same directory, you can import like this:
try:
    from data_processor import preprocess_company_data
except ImportError:
    print("Could not import data_processor. Make sure data_processor.py is in the same directory.")
    print("Skipping automatic preprocessing and assuming preprocessed-dataset.json exists.")

# Define file paths
RAW_DATA_PATH = 'data/output.json'
PROCESSED_DATA_PATH = 'data/preprocessed-dataset.json'
PLOTS_DIR = 'plots' # Directory to save visualizations

# Create output directories if they don't exist
os.makedirs(os.path.dirname(PROCESSED_DATA_PATH), exist_ok=True)
os.makedirs(PLOTS_DIR, exist_ok=True)

print("Environment setup complete.")

# 1. Preprocessing Stage (Execute if raw data is available)
# In a real pipeline, the web scraping script would generate RAW_DATA_PATH
# Here, we can call your preprocessing function if output.json exists or is generated.

# --- Placeholder for Web Scraping ---
# If you run a separate web scraping script, it would generate RAW_DATA_PATH.
# For now, let's assume RAW_DATA_PATH exists or you manually create a dummy one for testing.
# Example:
# from web_scraper import scrape_industrie_data
# scrape_industrie_data(RAW_DATA_PATH)
# -----------------------------------

# Ensure raw data exists or create dummy for demonstration if running directly without scraper
if not os.path.exists(RAW_DATA_PATH):
    print(f"Raw data file '{RAW_DATA_PATH}' not found. Creating a dummy for demonstration.")
    dummy_data = [
        {"company_name": "Test Inc.", "employees": "100-200", "establish_date": "Founded 1990", "money": "10 Mio. €", "phone": "+49 123456", "url": "test.com", "website": "testinc.com", "email": "info@testinc.com", "fax": "N/A", "address": "Some Street 1"},
        {"company_name": "Another Corp", "employees": "50", "establish_date": "Est. 2005", "money": "$5 Million", "phone": "+1 987654", "url": "another.com", "website": "anothercorp.com", "email": "contact@anothercorp.com", "fax": "N/A", "address": "Another Blvd 2"},
        {"company_name": "Third Company", "employees": "N/A", "establish_date": "unknown", "money": "2 Mrd. CHF", "phone": "+41 112233", "url": "third.com", "website": "thirdco.ch", "email": "hello@thirdco.ch", "fax": "N/A", "address": "Rue du Canton 3"},
        {"company_name": "Customer Focused", "employees": "20", "establish_date": "2010", "money": "Kundenbetreuung", "phone": "+49 998877", "url": "customer.com", "website": "customerfocus.de", "email": "support@customerfocus.de", "fax": "N/A", "address": "Kundenweg 4"},
        {"company_name": "Fourth Company", "employees": "5000", "establish_date": "1985", "money": "500 Million Euro", "phone": "+49 554433", "url": "fourth.com", "website": "fourthco.de", "email": "info@fourthco.de", "fax": "N/A", "address": "Vierte Straße 5"}
    ]
    with open(RAW_DATA_PATH, 'w', encoding='utf-8') as f:
        for item in dummy_data:
            json.dump(item, f, ensure_ascii=False)
            f.write('\n')
    print("Dummy output.json created for EDA.")

# Run preprocessing
preprocess_company_data(RAW_DATA_PATH, PROCESSED_DATA_PATH)

# Load the processed data
print(f"Loading processed data from {PROCESSED_DATA_PATH}...")
try:
    df = pd.read_json(PROCESSED_DATA_PATH, lines=True)
    print("Data loaded successfully.")
except Exception as e:
    print(f"Error loading processed data: {e}")
    print("Please ensure 'preprocessed-dataset.json' is correctly formatted JSONL.")
    exit() # Exit if data cannot be loaded, as further steps will fail.

# Convert numerical columns to nullable integer type for better memory and clarity
df['employees'] = df['employees'].astype('Int64')
df['establish_date'] = df['establish_date'].astype('Int64')
df['money'] = df['money'].astype('Int64') # Using Int64 for money too, as it's an integer after processing

print("\n--- Initial DataFrame Info ---")
df.info()
print("\n--- First 5 Rows ---")
print(df.head())

# 2. Basic Statistics

print("\n--- Calculating Basic Statistics ---")

string_attributes = ["url", "company_name", "website", "email", "phone", "fax", "address"]

# Count number of available values for each string attribute
count_stats = df[string_attributes].agg(['count'])
print("\nCounting Available Values for String Attributes:")
print(count_stats, '\n')

# For the companies their page is not found we only have their url in our dataset.
url_count = count_stats.loc['count', 'url']
company_name_count = count_stats.loc['count', 'company_name']
count_not_found = url_count - company_name_count

print(f'The pages of {count_not_found} companies are NOT found.\n')

# Calculate mean, median, and standard deviation for numerical attributes
numerical_attributes = ['employees', 'establish_date', 'money']
numerical_stats = df[numerical_attributes].agg(['count', 'mean', 'median', 'std'])

# Display numerical stats, rounding for clarity and casting to Int64 where appropriate
numerical_stats = numerical_stats.round(2) # Round floats to 2 decimal places
# Convert count, median to Int64 if they are whole numbers
numerical_stats.loc['count'] = numerical_stats.loc['count'].astype('Int64')
# For median, only convert if it's a whole number
for col in numerical_attributes:
    if numerical_stats.loc['median', col] == numerical_stats.loc['median', col].astype(int):
        numerical_stats.loc['median', col] = numerical_stats.loc['median', col].astype('Int64')


print("Numerical Statistics:")
print(numerical_stats)

# Extract the phone country code
df['phone_country_code'] = df['phone'].str.extract(r'(\+\d+)')

# Phone to country mapping
phone_to_country = {
    '+1': 'United States',
    '+44': 'United Kingdom',
    '+49': 'Germany',
    '+41': 'Switzerland',
    '+43': 'Austria',
    '+31': 'Netherlands',
    '+39': 'Italy',
    '+33': 'France',
    '+32': 'Belgium',
    '+45': 'Denmark'
}

# Map phone code to country name
df['country_name'] = df['phone_country_code'].map(phone_to_country)

# Count the frequency of each country
country_count = df['country_name'].value_counts()
top_10_countries = country_count.head(10)

print("\nTop 10 country code name counts based on phone numbers:")
for index, value in top_10_countries.items():
    print(f"{index}: {value}")

# Add: Correlation Analysis for numerical attributes
print("\n--- Correlation Matrix for Numerical Attributes ---")
# Drop rows with any NaN in numerical attributes for correlation calculation
df_numerical_for_corr = df[numerical_attributes].dropna()
if not df_numerical_for_corr.empty:
    correlation_matrix = df_numerical_for_corr.corr()
    print(correlation_matrix)

    # Optional: Visualize correlation matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
    plt.title('Correlation Matrix of Numerical Attributes')
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'correlation_matrix.png'))
    plt.show()
else:
    print("Not enough data with complete numerical attributes to calculate correlation matrix.")


# 3. Visualization

print("\n--- Generating Visualizations ---")

# Bar chart for Top 10 Country Code Names
total_entries = df['phone_country_code'].count()
# Calculate the percentage for each country
country_percentage = (country_count / total_entries) * 100
# Take the top 10 most frequent countries
top_10_country_names = country_percentage.head(10)

plt.figure(figsize=(12, 6))
ax = sns.barplot(x=top_10_country_names.index, y=top_10_country_names.values, palette='viridis') # Added palette

# Add percentage labels to each bar
for p in ax.patches:
    ax.annotate(f"{p.get_height():.2f}%",
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='baseline', fontsize=10, color='black', xytext=(0, 5),
                textcoords='offset points')

plt.title('Top 10 Country Code Names by Percentage')
plt.xlabel('Country Name')
plt.ylabel('Percentage')
plt.tight_layout() # Adjust layout to prevent labels from overlapping
plt.savefig(os.path.join(PLOTS_DIR, 'top_10_countries_barplot.png')) # Save plot
plt.show()

# CDF of the number of employees
# Drop nulls from the 'employees' column for this specific plot
df_employees_cleaned = df.dropna(subset=['employees'])

if not df_employees_cleaned.empty:
    sorted_employees = df_employees_cleaned['employees'].sort_values()
    cdf_employees = sorted_employees.value_counts().sort_index().cumsum() / sorted_employees.shape[0]

    plt.figure(figsize=(10, 6))
    plt.plot(cdf_employees.index, cdf_employees, linestyle='-', color='skyblue')
    plt.xscale('log')
    plt.xlabel('Number of Employees (Log Scale)')
    plt.ylabel('CDF')
    plt.title('CDF of Number of Employees')
    plt.grid(True, which="both", ls="--", c="0.7") # Improved grid
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'cdf_employees.png')) # Save plot
    plt.show()
else:
    print("Skipping CDF of employees: No valid employee data after dropping NaNs.")


# Histogram for 'establish_date' attribute
# Drop nulls for plotting
df_establish_date_cleaned = df.dropna(subset=['establish_date'])
if not df_establish_date_cleaned.empty:
    plt.figure(figsize=(10, 6))
    sns.histplot(df_establish_date_cleaned['establish_date'], bins=30, kde=False, color='lightcoral', edgecolor='black') # Added color, edgecolor
    plt.title('Histogram of Establishment Date')
    plt.xlabel('Establishment Date')
    plt.ylabel('Frequency')
    plt.grid(axis='y', linestyle='--', alpha=0.7) # Improved grid
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'hist_establishment_date.png')) # Save plot
    plt.show()
else:
    print("Skipping Histogram of establishment date: No valid establishment date data after dropping NaNs.")

# CDF of financial status
# Drop nulls from the 'money' column for this specific plot
df_money_cleaned = df.dropna(subset=['money'])
if not df_money_cleaned.empty:
    sorted_money = df_money_cleaned['money'].sort_values()
    cdf_money = sorted_money.value_counts().sort_index().cumsum() / sorted_money.shape[0]

    plt.figure(figsize=(10, 6))
    plt.plot(cdf_money.index, cdf_money, linestyle='-', color='mediumseagreen') # Added color
    plt.xscale('log')
    plt.xlabel('Money in Euros (Log Scale)')
    plt.ylabel('CDF')
    plt.title('CDF of Financial Status (Euros) with Log Scale')
    plt.grid(True, which="both", ls="--", c="0.7") # Improved grid
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'cdf_financial_status.png')) # Save plot
    plt.show()
else:
    print("Skipping CDF of financial status: No valid money data after dropping NaNs.")

# Relationship between financial status and number of employees (Scatter Plot)
df_scatter = df.dropna(subset=['money', 'employees'])
if not df_scatter.empty:
    plt.figure(figsize=(10, 6))
    plt.scatter(df_scatter['money'], df_scatter['employees'], c='blue', alpha=0.6) # Added alpha
    plt.xlabel('Money in Euros')
    plt.ylabel('Number of Employees')
    plt.title('Relationship between Money and Number of Employees')
    plt.grid(True, linestyle='--', alpha=0.7) # Improved grid
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'scatter_money_employees.png')) # Save plot
    plt.show()
else:
    print("Skipping Scatter Plot: Not enough valid data for Money and Employees after dropping NaNs.")


# Relationship between financial status and country (Bar Plot)
df_country_money = df.dropna(subset=['money', 'country_name'])
if not df_country_money.empty:
    # Group the data by country and calculate the mean money
    grouped_data = df_country_money.groupby('country_name')['money'].mean().sort_values(ascending=False)

    plt.figure(figsize=(15, 7)) # Increased figure size
    grouped_data.plot(kind='bar', color='teal', edgecolor='black') # Added color, edgecolor
    plt.xlabel('Country Name')
    plt.ylabel('Average Financial Status (Euros)') # Clarified y-label
    plt.title('Average Financial Status by Country') # Simplified title
    plt.xticks(rotation=45, ha='right') # Rotate x-labels for better visibility, adjusted alignment
    plt.grid(axis='y', linestyle='--', alpha=0.7) # Added grid
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, 'bar_avg_money_by_country.png')) # Save plot
    plt.show()
else:
    print("Skipping Bar Plot (Avg Money by Country): Not enough valid data for Money and Country Name.")

print("\nEDA complete. All plots saved to the 'plots' directory.")
